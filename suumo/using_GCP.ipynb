{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8cf3d6-39f3-401e-965c-b31202e06e01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 目的  \n",
    "家賃、駅徒歩などの条件に合う物件を見つけたい。作成したモデルを使ってお得物件を発見したい。  \n",
    "学生時代新宿周辺に住んでいたこともあって、新宿区の物件に興味があるので調査  \n",
    "### GCPを用いて、バッチ処理、スクレイピング、ストレージの一連の流れを実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d1fe7-3b0e-4dba-9708-df60653de5a8",
   "metadata": {},
   "source": [
    "ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151abeaa-a305-41d7-b54d-d14144f178b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn import preprocessing\n",
    "#探索的データ解析\n",
    "import pandas_profiling as pdp \n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_rows',100)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from google.cloud import storage as gcs # gcsへデータを送るのに必要\n",
    "from google.cloud import bigquery as gbq # BigQueryのテーブルにデータを挿入するのに必要\n",
    "import io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466afc81-e856-43b7-8a38-6fda0c1ed3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f148b70-dff9-494c-9dd0-98eafd6c2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#滋賀県の5件のデータ\n",
    "#https://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ta=10&sc=10380&cb=0.0&ct=9999999&et=9999999&cn=9999999&mb=0&mt=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&fw2="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c4c633-9f22-4e71-a4b3-f746775158d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#Webスクレイピングによく使用されるライブラリの一つで、HTMLやXMLなどのマークアップ言語で書かれた文書をパースして、文書内の情報を抽出するための機能\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import datetime\n",
    "from google.cloud import storage as gcs # gcsへデータを送るのに必要\n",
    "from google.cloud import bigquery as gbq # BigQueryのテーブルにデータを挿入するのに必要\n",
    "# スクレイピングの開始点のURL\n",
    "url = \"https://suumo.jp/jj/chintai/ichiran/FR301FC005/?ar=030&bs=040&ra=013&rn=0045&ek=004506820&cb=0.0&ct=9999999&mb=0&mt=9999999&et=9999999&cn=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&sngz=&po1=09&po2=99&pc=100\"\n",
    "\n",
    "#\"https://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ta=10&sc=10380&cb=0.0&ct=9999999&et=9999999&cn=9999999&mb=0&mt=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&fw2=\"\n",
    "\n",
    "# スクレイピングを実行する関数\n",
    "def suumo_scraping():\n",
    "    name = []\n",
    "    station = []\n",
    "    price = []\n",
    "    sikikinreikin = []\n",
    "    room = []\n",
    "    age = []\n",
    "    address = []\n",
    "    count_new_list = [] \n",
    "\n",
    "    urls=requests.get(url)\n",
    "    # 連続してアクセスするのを防ぐために3秒待つ\n",
    "    time.sleep(3)\n",
    "    #urls.encodingは、サイトの文字コードを表す文字列を返す。\n",
    "     #urls.apparent_encodingを使って、文字コードが正しく設定されていない場合に、自動的に正しい文字コードを設定するために使用\n",
    "    urls.encoding = urls.apparent_encoding \n",
    "    \n",
    "    #、指定したURLから取得したHTMLドキュメントを解析し、特定の要素を抽出する\n",
    "    soup=BeautifulSoup()\n",
    "     #BeautifulSoupを使って、URLから取得したHTMLコンテンツを解析して、パース可能なオブジェクトを作成\n",
    "     #第一引数には、解析したいHTMLのコンテンツが含まれた文字列を渡し、第二引数には、使用する解析器を指定します。ここでは、\"html.parser\"\n",
    "    soup=BeautifulSoup(urls.content,\"html.parser\")\n",
    "    #soupオブジェクトから、\"ol\"タグでclass属性が\"pagination-parts\"である要素を抽出\n",
    "    get_url = soup.find(\"ol\",class_=\"pagination-parts\")\n",
    "    \n",
    "    # 物件のページ数を取得\n",
    "    # 指定したHTMLドキュメントから\"li\"タグのテキストを抽出し、リストに格納\n",
    "    num_list =[]\n",
    "    for i in get_url.find_all(\"li\"):  #get_urlというオブジェクトから、\"li\"タグのすべての要素を検索\n",
    "        num_list.append(i.text)       #append()メソッドは、リストの最後に指定された値を追加するために使用されます。\n",
    "                                      #ここでは、i.textをnum_listに追加しています。i.textは、i要素内に含まれるテキストを表している。\n",
    "    num = int(num_list[10]) + 1       #リストnum_listの11番目の要素を取得し、整数値に変換してから1を足している。これにより、取得したページ数に1を加えた値がnumに格納される。\n",
    "\n",
    "    \n",
    "    # ページ数分だけスクレイピングを実行\n",
    "    for p in range(1,num):\n",
    "        page=str(p)\n",
    "        url_2=\"https://suumo.jp/jj/chintai/ichiran/FR301FC005/?ar=030&bs=040&ra=013&rn=0045&ek=004506820&cb=0.0&ct=9999999&mb=0&mt=9999999&et=9999999&cn=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&sngz=&po1=09&po2=99&pc=100\" + \"&page=\" + page\n",
    "        urls=requests.get(url_2)  #requests.get()関数を使用してHTMLデータを取得\n",
    "        # 連続してアクセスするのを防ぐために3秒待つ\n",
    "        time.sleep(3)\n",
    "        soup=BeautifulSoup(urls.content,\"html.parser\")\n",
    "        \n",
    "        # 「本日の新着」「新着」のタグを検索\n",
    "         #soupのHTML内から「class=\"ellipse_pct ellipse_pct--red\"」というクラスを持つ「<span>」タグを探し,\n",
    "         #この「<span>」タグには、「本日の新着」という文言が含まれており、それを表すために使われています。このコードが見つけたすべての「<span>」タグは、リストとして変数「house_info」に格納\n",
    "        house_info = soup.find_all(\"span\",class_=\"ellipse_pct ellipse_pct--red\")\n",
    "        \n",
    "        # 「本日の新着」「新着」のタグの中で「本日の新着」の数をカウント\n",
    "        \n",
    "         #各ページにおいて「本日の新着」の件数を数えて、リストとして保存\n",
    "        count_new = 0\n",
    "        for i in house_info:  #前のコードで取得した「<span>」タグのリスト「house_info」をループ処理\n",
    "            if i.text == \"本日の新着\":  #その中に含まれるテキストが「本日の新着」である場合に、変数「count_new」を1つ増やす。\n",
    "                count_new += 1\n",
    "        count_new_list.append(count_new)  #各ページにおいて「本日の新着」が何件あるかをカウントし、「count_new_list」リストに追加\n",
    "        \n",
    "        # ページ内の「本日の新着」の数が0でないならスクレイピングを実行\n",
    "        if count_new != 0:   \n",
    "            #'<a>'タグの中から、classが\"js-cassetLinkHref\"であるものを所得\n",
    "            house_name = soup.find_all(\"a\",class_=\"js-cassetLinkHref\")\n",
    "            #最寄り駅の名前の取得\n",
    "             #<div>タグの中から、styleがfont-weight:boldであるものをすべて取得\n",
    "            station_name = soup.find_all(\"div\",style=\"font-weight:bold\")\n",
    "            #'urls'からテーブルをスクレイピング\n",
    "            table_data = pd.read_html(urls.content)\n",
    "            #スクレイピングした情報をリストに追加\n",
    "             #house_nameとstation_nameは、それぞれ物件名と最寄り駅名が含まれるタグを取得\n",
    "            for h in house_name:\n",
    "                name.append(h.text)\n",
    "            for s in station_name:\n",
    "                station.append(s.text)\n",
    "            #物件情報の取得\n",
    "            for i in range(0,count_new):\n",
    "                #table_dataには、物件の価格、間取り、築年数、住所、敷金・礼金などがテーブル形式で格納\n",
    "                table = table_data[i]\n",
    "                #最初のテーブルの最初の行の最初の列に格納された価格をpriceリストに追加\n",
    "                price.append(table.iloc[0,0])\n",
    "                room.append(table.iloc[0,2])\n",
    "                age.append(table.iloc[0,3])\n",
    "                address.append(table.iloc[0,4])\n",
    "                sikikinreikin.append(table.iloc[0,1])\n",
    "        # ページ内の「本日の新着」が0ならスクレイピングをやめる\n",
    "        else:\n",
    "            break\n",
    "    #スクレイピングした情報をリストにまとめて返す\n",
    "    return name, station, price, sikikinreikin, room, age, address, count_new_list\n",
    "\n",
    "# 前処理を実行する関数 スクレイピングの際に余計な空白等がついてくるのでここで除去する\n",
    "# このコードだけだとイメージしにくい。手元の環境でデータを見ながらのほうがイメージしやすい\n",
    " #preprocessingの定義。suumo_scraping関数によって、取得したデータが格納されている。\n",
    "def preprocessing(name, station, price, sikikinreikin, room, age, address, count_new_list):\n",
    "    station_line_list = []\n",
    "    time_move_list = []\n",
    " #stationリストから「駅名」と「路線名と所要時間」を分離し、それぞれstation_line_listとtime_move_listに追加\n",
    "    for i in station:\n",
    "        #split()メソッドを用いて、各駅名を空白で分割し、その結果得られるリストの0番目を路線名\n",
    "        station_line_list.append(i.split(\" \")[0])\n",
    "        #1番目を所要時間として、それぞれstation_line_listとtime_move_listに追加\n",
    "        time_move_list.append(i.split(\" \")[1])\n",
    "\n",
    "    station_list = []\n",
    "    line_list = []\n",
    "\n",
    "    for i in station_line_list:\n",
    "        #station_line_listリストには、駅名と路線名が\"/\"でつながった文字列が格納されているため、まずはsplit()関数を使って\"/\"で分割し、駅名と路線名のリストを作成\n",
    "        #、駅名と路線名をそれぞれappend()関数でstation_listとline_listに格納\n",
    "        station_list.append(i.split(\"/\")[1])\n",
    "        line_list.append(i.split(\"/\")[0])\n",
    "\n",
    "    move_list =[]\n",
    "    time_list = []\n",
    "\n",
    "    for i in time_move_list:\n",
    "        #time_move_list の要素をループで取り出して、文字列中に \"歩\" が含まれる場合は move_list に徒歩を追加\n",
    "        if \"歩\" in i:\n",
    "            move_list.append(\"徒歩\")\n",
    "            #移動時間に含まれる非数字の文字を除去するため、re.sub(r\"\\D\", \"\", i) を使って、time_list に数値だけを追加\n",
    "            time_list.append(re.sub(r\"\\D\", \"\", i))\n",
    "        #それ以外の場合は \"バス\" を追加\n",
    "        else:\n",
    "            move_list.append(\"バス\")\n",
    "            time_list.append(re.sub(r\"\\D\", \"\", i))\n",
    "\n",
    "    df=pd.DataFrame()        \n",
    "    \n",
    "    #それぞれのリストに各列を追加する。\n",
    "    df[\"station\"] = pd.Series(station_list)\n",
    "    df[\"line\"] = pd.Series(line_list)\n",
    "    df[\"move\"] = pd.Series(move_list)\n",
    "    df[\"time_to_station_min\"] = pd.Series(time_list).astype(float)\n",
    "\n",
    "  #家賃と管理費をそれぞれ抜き出し、価格リストと管理費リストを作成するための処理\n",
    "    price_list = []\n",
    "    admin_list = []\n",
    "\n",
    "    for i in price: #変数priceには、スクレイピングした不動産情報から取得した文字列型の価格情報がリストとして格納されている\n",
    "       #priceリストから各要素を取り出して、スペースで分割した後に家賃と管理費を抜き出して、price_listとadmin_listに追加\n",
    "        price_list.append(i.split(\" \")[0].replace(\"万円\",\"\"))\n",
    "        admin_list.append(i.split(\" \")[3].replace(\"円\",\"\"))\n",
    "\n",
    "    admin_fee_list = []\n",
    "   #物件の管理費用を管理費用のリストから取得\n",
    "    for i in admin_list: #admin_list リストの要素を一つずつ取り出し、i という名前で参照\n",
    "        #i が \"-\" であれば、管理費用が存在しないと判断し、admin_fee_list に \"0\" を追加\n",
    "        if i == \"-\":\n",
    "            admin_fee_list.append(\"0\")\n",
    "        #i が \"-\" 以外であれば、管理費用が存在し、その値をadmin_fee_list に追加\n",
    "        else:\n",
    "            admin_fee_list.append(i)\n",
    "\n",
    "    df[\"price_10k\"] = pd.Series(price_list).astype(float)\n",
    "    df[\"admin_fee\"] = pd.Series(admin_fee_list).astype(float)\n",
    "\n",
    "    sikikin_pre = []\n",
    "    reikin_pre = []\n",
    "    deposit_pre = []\n",
    "    sikibiki_pre = []\n",
    "#i.split(\" \")[0]で敷金の金額を、i.split(\" \")[2]で礼金の金額を、\n",
    "#i.split(\" \")[4]で敷引きの金額を、i.split(\" \")[6]で敷引き以外の償却費の金額を取り出す\n",
    "    for i in sikikinreikin:\n",
    "        sikikin_pre.append(i.split(\" \")[0])\n",
    "        reikin_pre.append(i.split(\" \")[2])\n",
    "        deposit_pre.append(i.split(\" \")[4])\n",
    "        sikibiki_pre.append(i.split(\" \")[6])\n",
    "\n",
    "    sikikin_list = []\n",
    "    reikin_list = []\n",
    "    deposit_list = []\n",
    "    sikibiki_list = []\n",
    "\n",
    "    for i in sikikin_pre:\n",
    "        a = i.split(\"敷\")[1]\n",
    "       #万円で表されている場合は、万円の部分を除いて数値のみを残し、万円で表されていない場合は、0として扱い\n",
    "        if \"万円\" in a:\n",
    "            sikikin_list.append(a.replace(\"万円\",\"\"))\n",
    "        else:\n",
    "            sikikin_list.append(0)\n",
    "\n",
    "    for i in reikin_pre:\n",
    "        a = i.split('礼')[1]\n",
    "        if \"万円\" in a:\n",
    "            reikin_list.append(a.replace(\"万円\",\"\"))\n",
    "        else:\n",
    "            reikin_list.append(0)\n",
    "\n",
    "    for i in deposit_pre: #保証金\n",
    "        a = i.split('\\xa0')[1]\n",
    "        if \"万円\" in a:\n",
    "            deposit_list.append(a.replace(\"万円\",\"\"))\n",
    "        else:\n",
    "            deposit_list.append(0)\n",
    "\n",
    "    for i in sikibiki_pre: #敷引き\n",
    "        a = i.split(\"\\xa0\")[1]\n",
    "        if \"万円\" in a:\n",
    "            sikibiki_list.append(a.replace(\"万円\",\"\"))\n",
    "        elif \"-\" in a:\n",
    "            sikibiki_list.append(0)\n",
    "        else:\n",
    "            sikibiki_list.append(\"実費\")\n",
    "\n",
    "    df[\"sikikin_10k\"] = pd.Series(sikikin_list).astype(float)\n",
    "    df[\"reikin_10k\"] = pd.Series(reikin_list).astype(float)\n",
    "    df[\"deposit_10k\"] = pd.Series(deposit_list).astype(float)\n",
    "    df[\"sikibiki_10k\"] = pd.Series(sikibiki_list)\n",
    "\n",
    "    room_list = []\n",
    "    area_pre = []\n",
    "    direction_pre = []\n",
    "\n",
    "    for i in room:\n",
    "        room_list.append(i.split(\" \")[0])\n",
    "        area_pre.append(i.split(\" \")[2])\n",
    "        direction_pre.append(i.split(\" \")[4])\n",
    "\n",
    "    area_list = []\n",
    "\n",
    "    for i in area_pre:\n",
    "        area_list.append(i.replace(\"m2\",\"\"))\n",
    "\n",
    "    df[\"room\"] = pd.Series(room_list)\n",
    "    df[\"area_m2\"] = pd.Series(area_list)\n",
    "    df[\"direction\"] = pd.Series(direction_pre)\n",
    "\n",
    "    type_list = []\n",
    "    age_pre = []\n",
    "\n",
    "    for i in age:\n",
    "        type_list.append(i.split(\" \")[0])\n",
    "        age_pre.append(i.split(\" \")[2])\n",
    "\n",
    "    age_list = []\n",
    "\n",
    "    for i in age_pre:\n",
    "        if i == \"新築\":\n",
    "            age_list.append(0)\n",
    "        else:\n",
    "            age_list.append(re.sub(r\"\\D\", \"\", i))\n",
    "\n",
    "    df[\"type\"] = pd.Series(type_list)\n",
    "    df[\"age_year\"] = pd.Series(age_list).astype(float)\n",
    "\n",
    "    df[\"scraping_date\"] = datetime.date.today()\n",
    "    df[\"name\"] = pd.Series(name)\n",
    "    df[\"address\"] = pd.Series(address)\n",
    "\n",
    "    id_range = 0\n",
    "    for i in count_new_list:\n",
    "        id_range = i + id_range\n",
    "\n",
    "   #現在の日付からID番号のリストを作成する\n",
    "    id_list = []\n",
    "    \n",
    "    #datetime.date.today()を使って、現在の日付を取得\n",
    "    to_day = str(datetime.date.today())\n",
    "    #日付の文字列を作成するために、\"-\"を削除\n",
    "    to_day = to_day.replace(\"-\",\"\")\n",
    "    #id_range回繰り返しを行い、iを文字列に変換してID番号を生成\n",
    "    for i in range(0,id_range):\n",
    "        if i < 10:\n",
    "            i = str(i)\n",
    "            id_list.append(to_day + \"000\"  + i)            \n",
    "        elif i >= 10 and i < 100:\n",
    "            i = str(i)\n",
    "            id_list.append(to_day + \"00\" + i)\n",
    "        elif i >= 100 and i < 1000:\n",
    "            i = str(i)\n",
    "            id_list.append(to_day + \"0\" + i)            \n",
    "        else:\n",
    "            i = str(i)\n",
    "            id_list.append(to_day + i) \n",
    "\n",
    "    df[\"scraping_id\"] = pd.Series(id_list)\n",
    "    \n",
    "    #dfを作成\n",
    "    df = df.reindex(columns=[\"scraping_id\",\"scraping_date\",\"name\",\"price_10k\",\"age_year\",\"admin_fee\",\"sikikin_10k\",\"reikin_10k\",\"deposit_10k\",\"sikibiki_10k\",\"line\",\"station\",\"move\",\"time_to_station_min\",\"room\",\"area_m2\",\"direction\",\"type\",\"address\"])\n",
    "    # 最後のページのスクレイピングでは「本日の新着」以外のデータも混ざっている\n",
    "    # pd.read_html(urls.content)で取得した賃貸価格など\n",
    "    # それ以外で取得した物件名などは「本日の新着」分のデータしか取得していないのでNULLの部分が出てくる\n",
    "    # NULLが入っているデータは余分なデータなので削除する\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df\n",
    "# データをGCSへcsvファイルで保存する関数\n",
    "def send_storage(df):\n",
    "    #project_id と bucket_name で指定されたGCSのプロジェクトとバケットを利用\n",
    "    project_id = \"rapid-stage-380007\" \n",
    "    bucket_name = \"suumo_bucket01\" \n",
    "    \n",
    "   #suumo_bucket01 バケット内の suumo_data/test ディレクトリにファイルを保存するよう指定\n",
    "    #gcs_path_1 で指定されたパスに _YYYYMMDD.csv のファイル名を付けて、データフレーム df をアップロード\n",
    "    gcs_path_1 = \"suumo_data/test\" # バケットのファイルまでのパス\n",
    "    \n",
    "    # ファイル名でスクレイピングした日付がわかるようにする\n",
    "    to_day = str(datetime.date.today())\n",
    "    to_day = to_day.replace(\"-\",\"\")\n",
    "    \n",
    "    client = gcs.Client(project_id)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    \n",
    "    #bucket.blob() メソッドを使用して、アップロード先のファイルを作成\n",
    "    blob_gcs_1 = bucket.blob(gcs_path_1 + \"_\" + to_day + \".csv\")\n",
    "    \n",
    "    #to_csv() メソッドで作成した CSV データを、blob.upload_from_string() メソッドを使用してアップロード\n",
    "     #blob オブジェクトには、先ほど作成したアップロード先のファイルが格納\n",
    "    blob_gcs_1.upload_from_string(data=df.to_csv(index=False))\n",
    "\n",
    "# BigQueryのテーブルにDFデータをインサートする関数\n",
    " #この関数を呼び出すことで、指定したテーブルにDataFrameのデータが挿入される\n",
    "def bigquery_insert(df):\n",
    "    #gbq.Client()を呼び出して、BigQuery APIクライアントを初期化\n",
    "    client = gbq.Client()\n",
    "    \n",
    "    #client.get_table()を使用して、挿入先のテーブルを取得\n",
    "    #suumo01_tableというテーブルを取得\n",
    "    table = client.get_table(\"rapid-stage-380007.suumo01.suumo01_table\")\n",
    "    \n",
    "    #client.insert_rows()を使用して、DataFrameの値をテーブルに挿入\n",
    "    client.insert_rows(table, df.values.tolist())\n",
    "\n",
    "# Cloud Functionで実行する関数\n",
    "# Cloud Functionsのエントリポイントであるmain関数を定義\n",
    "def main(event, context):\n",
    "    #main関数内で、suumo_scraping関数を呼び出して、スクレイピングしたデータを取得\n",
    "    name, station, price, sikikinreikin, room, age, address, count_new_list = suumo_scraping()\n",
    "\n",
    "    #取得したデータを前処理するためにpreprocessing関数を呼び出します。\n",
    "     #前処理されたデータは、dfというDataFrameオブジェクトに格納\n",
    "    df = preprocessing(name, station, price, sikikinreikin, room, age, address, count_new_list)\n",
    "    \n",
    "    #send_storage関数を呼び出して、前処理されたデータをGoogle Cloud Storageにアップロード\n",
    "    send_storage(df)\n",
    "    \n",
    "    #bigquery_insert関数を呼び出して、前処理されたデータをBigQueryに挿入\n",
    "    bigquery_insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7f5a2-0afe-41ca-bff0-4864c7169c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#requiremensts.txt\n",
    "beautifulsoup4>=4.11.1  \n",
    "requests>=2.28.1  \n",
    "pandas>=1.5.3  \n",
    "google-cloud-storage>=2.7.0  \n",
    "google-cloud-bigquery>=3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc0eb214-e2f3-4b4f-9772-755e4a51ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('suumo_data_test_20230411.txt', 'r',encoding='utf-8') as df:\n",
    "    df_content = df.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28b40af-6faf-4d23-ab70-9c546b77efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbef119b-137f-47b6-8a50-b1f1ddeb4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# タブ区切りのテキストファイルをDataFrameに変換する\n",
    "df = pd.read_csv('suumo_data_test_20230411.txt',delimiter=',',names=['scraping_id','scraping_date','name','price_10k','age_year',\n",
    "                                                          'admin_fee','sikikin_10k','reikin_10k','deposit_10k','sikibiki_10k',\n",
    "                                                          'line','station','move','time_to_station_min','room',\n",
    "                                                          'area_m2','direction','type','address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306b0964-6250-4b7d-a17c-c6c8434fc8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d3b15d-7fa1-44eb-b900-50a735e2f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル\n",
    "df.to_csv('suumo_sp_folder/suumo_sp01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8334a27d-4f3e-4864-86ed-7f8cb62dbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('suumo_sp_folder/suumo_sp01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e06c2ba-e780-4d0c-b57b-fd260eb8b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('suumo_data_test_20230411.txt', 'r',encoding='utf-8') as df:\n",
    "    df_content = df.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c27d7b-59d5-4305-8e81-ef00bc60a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792f0cb9-7d13-4407-b823-9a79d218b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# タブ区切りのテキストファイルをDataFrameに変換する\n",
    "df = pd.read_csv('suumo_data_test_20230411.txt',delimiter=',',names=['scraping_id','scraping_date','name','price_10k','age_year',\n",
    "                                                          'admin_fee','sikikin_10k','reikin_10k','deposit_10k','sikibiki_10k',\n",
    "                                                          'line','station','move','time_to_station_min','room',\n",
    "                                                          'area_m2','direction','type','address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a1dd82-6097-46f2-8ccc-4c565f727fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0行目は必要ないので除去\n",
    "df = df.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c52b2e-b2fc-4a44-9068-c649647b03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイル\n",
    "df.to_csv('suumo_sp_folder/suumo_sp01.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91b6c6a6-bc3c-4cf7-8c39-9a4c7b73da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('suumo_sp_folder/suumo_sp01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a533dfc2-9ea4-4a49-9fea-06246e1b8a58",
   "metadata": {},
   "source": [
    "# 2つ目の関数  \n",
    "スクレイピングして作成したDFからお得な家賃の物件を抽出する。  \n",
    "GCFに下記のコードを入力する。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bf2b5cc-23e4-4399-855b-d6e4f41475e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "#エントリーポイント：mp_main\n",
    "import base64\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def read_csv_from_gcs(bucket_name, file_path):\n",
    "    \"\"\"Reads a CSV file from Google Cloud Storage and returns a Pandas DataFrame.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(file_path)\n",
    "    data = blob.download_as_string()\n",
    "    df = pd.read_csv(io.BytesIO(data),dtype=str)\n",
    "    return df\n",
    "\n",
    "def write_csv_to_gcs(df, bucket_name, file_path):\n",
    "    \"\"\"Writes a Pandas DataFrame to a CSV file in Google Cloud Storage.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_string(df.to_csv(index=False), 'text/csv')\n",
    "\n",
    "def mp_main(event, context):\n",
    "    \"\"\"Triggered from a message on a Cloud Pub/Sub topic.\n",
    "    Args:\n",
    "         event (dict): Event payload.\n",
    "         context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    #pubsub_message = base64.b64decode(event['data']).decode('utf-8')\n",
    "    #print(pubsub_message)\n",
    "    \n",
    "    df1 = read_csv_from_gcs('suumo_bucket01', 'suumo_data/test_20230411.csv')\n",
    "\n",
    "    #カテゴリ変数のカラムを指定して、まとめて処理\n",
    "    def encode_categorical(df,cols):\n",
    "        for col in cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = pd.Series(le.fit_transform(df[col]))\n",
    "    \n",
    "        return df\n",
    "    df1 = encode_categorical(df1,cols=[\"scraping_date\",\"name\",\"line\",\"station\",\"move\",\"room\",\"direction\",\"type\",\"address\"])\n",
    "\n",
    "    X = df1.drop('price_10k', axis=1)\n",
    "    y = df1['price_10k']\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    df2 = df1.copy()\n",
    "    df2['market_rent'] = model.predict(X)\n",
    "    df2['price_10k'] = df2['price_10k'].astype(float)\n",
    "    df2['market_rent'] = df2['market_rent'].astype(float)\n",
    "\n",
    "    df2['rent_difference'] = df2['price_10k'] - df2['market_rent']\n",
    "\n",
    "    df2_sorted = df2.sort_values('rent_difference', ascending=True)\n",
    "    write_csv_to_gcs(df2_sorted, 'suumo_bucket01', 'suumo_mp_data/mp_file01.csv')\n",
    "\n",
    "    #if 'data' in event:\n",
    "    #    pubsub_message = base64.b64decode(event['data']).decode('utf-8')\n",
    "    #else:\n",
    "    #    pubsub_message = None\n",
    "\n",
    "# データをGCSへcsvファイルで保存する関数\n",
    "def send_storage(df2_sorted):\n",
    "    project_id = \"rapid-stage-380007\" \n",
    "    bucket_name = \"suumo_bucket01\" \n",
    "    gcs_path_2 = \"suumo_mp_data/mp_file01\" # バケットのファイルまでのパス\n",
    "    # ファイル名でスクレイピングした日付がわかるようにする\n",
    "    to_day = str(datetime.date.today())\n",
    "    to_day = to_day.replace(\"-\",\"\")\n",
    "    \n",
    "    client = gcs.Client(project_id)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob_gcs_2 = bucket.blob(gcs_path_2 + \"_\" + to_day + \".csv\")\n",
    "\n",
    "    blob_gcs_2.upload_from_string(data=df2_sorted.to_csv(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c3404-67af-48b5-b9ab-97252bbe5b19",
   "metadata": {},
   "source": [
    "#requirements.txt  \n",
    "pandas>=1.4.1\n",
    "google-cloud-storage>=2.1.0\n",
    "\n",
    "scikit-learn>=1.0.2\n",
    "lightGBM>=3.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b861dc27-3d5c-4c1b-ad3f-1350442de969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#カテゴリ変数のカラムを指定して、まとめて処理\n",
    "for col in cols:\n",
    "    le = LabelEncoder()\n",
    "    df1[col] = pd.Series(le.fit_transform(df1[col]))\n",
    "\n",
    "df1 = encode_categorical(df1,cols=[\"scraping_date\",\"name\",\"line\",\"station\",\"move\",\"room\",\"direction\",\"type\",\"address\"])\n",
    "\n",
    "X = df1.drop('price_10k', axis=1)\n",
    "y = df1['price_10k']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "df2 = df1.copy()\n",
    "df2['market_rent'] = model.predict(X)\n",
    "df2['price_10k'] = df2['price_10k'].astype(float)\n",
    "df2['market_rent'] = df2['market_rent'].astype(float)\n",
    "\n",
    "df2['rent_difference'] = df2['price_10k'] - df2['market_rent']\n",
    "\n",
    "df2_sorted = df2.sort_values('rent_difference', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3877fc00-7f27-4103-8218-0550e1f3e919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_10k</th>\n",
       "      <th>market_rent</th>\n",
       "      <th>rent_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>44.0</td>\n",
       "      <td>52.727688</td>\n",
       "      <td>-8.727688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>39.0</td>\n",
       "      <td>47.514988</td>\n",
       "      <td>-8.514988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>43.0</td>\n",
       "      <td>50.893050</td>\n",
       "      <td>-7.893050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>39.0</td>\n",
       "      <td>46.617498</td>\n",
       "      <td>-7.617498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>71.0</td>\n",
       "      <td>78.601456</td>\n",
       "      <td>-7.601456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>113.0</td>\n",
       "      <td>101.890808</td>\n",
       "      <td>11.109192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>113.0</td>\n",
       "      <td>101.620807</td>\n",
       "      <td>11.379193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>118.0</td>\n",
       "      <td>104.618361</td>\n",
       "      <td>13.381639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>117.0</td>\n",
       "      <td>102.908852</td>\n",
       "      <td>14.091148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>116.0</td>\n",
       "      <td>101.312785</td>\n",
       "      <td>14.687215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_10k  market_rent  rent_difference\n",
       "284       44.0    52.727688        -8.727688\n",
       "239       39.0    47.514988        -8.514988\n",
       "282       43.0    50.893050        -7.893050\n",
       "238       39.0    46.617498        -7.617498\n",
       "440       71.0    78.601456        -7.601456\n",
       "..         ...          ...              ...\n",
       "578      113.0   101.890808        11.109192\n",
       "579      113.0   101.620807        11.379193\n",
       "585      118.0   104.618361        13.381639\n",
       "584      117.0   102.908852        14.091148\n",
       "583      116.0   101.312785        14.687215\n",
       "\n",
       "[586 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sorted[['price_10k','market_rent','rent_difference']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c475a6d0-c588-48d0-9361-cb168a92ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scraping_id</th>\n",
       "      <th>scraping_date</th>\n",
       "      <th>name</th>\n",
       "      <th>price_10k</th>\n",
       "      <th>age_year</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>sikikin_10k</th>\n",
       "      <th>reikin_10k</th>\n",
       "      <th>deposit_10k</th>\n",
       "      <th>sikibiki_10k</th>\n",
       "      <th>line</th>\n",
       "      <th>station</th>\n",
       "      <th>move</th>\n",
       "      <th>time_to_station_min</th>\n",
       "      <th>room</th>\n",
       "      <th>area_m2</th>\n",
       "      <th>direction</th>\n",
       "      <th>type</th>\n",
       "      <th>address</th>\n",
       "      <th>market_rent</th>\n",
       "      <th>rent_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>52.727688</td>\n",
       "      <td>-8.727688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>47.514988</td>\n",
       "      <td>-8.514988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>50.893050</td>\n",
       "      <td>-7.893050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>46.617498</td>\n",
       "      <td>-7.617498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>78.601456</td>\n",
       "      <td>-7.601456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>113.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>101.890808</td>\n",
       "      <td>11.109192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>101.620807</td>\n",
       "      <td>11.379193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>104.618361</td>\n",
       "      <td>13.381639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>102.908852</td>\n",
       "      <td>14.091148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>116.0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>170</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>101.312785</td>\n",
       "      <td>14.687215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     scraping_id  scraping_date  name  price_10k  age_year  admin_fee  \\\n",
       "284          284              0    14       44.0         5         19   \n",
       "239          239              0   210       39.0         7          9   \n",
       "282          282              0   162       43.0         3         23   \n",
       "238          238              0   260       39.0         7          9   \n",
       "440          440              0   202       71.0        10         19   \n",
       "..           ...            ...   ...        ...       ...        ...   \n",
       "578          578              0   135      113.0        18          0   \n",
       "579          579              0   171      113.0         0         25   \n",
       "585          585              0   122      118.0         2          0   \n",
       "584          584              0    36      117.0         0         19   \n",
       "583          583              0   125      116.0         3         27   \n",
       "\n",
       "     sikikin_10k  reikin_10k  deposit_10k  sikibiki_10k  line  station  move  \\\n",
       "284            0           0            0             0     1        0     0   \n",
       "239           34          33            0             0     1        0     0   \n",
       "282            0           0            0             0     1        0     0   \n",
       "238           34          33            0             0     0        0     0   \n",
       "440           57          57            0             0     3        0     0   \n",
       "..           ...         ...          ...           ...   ...      ...   ...   \n",
       "578           91          83            0             0     1        0     0   \n",
       "579            0           0            0             0     3        0     0   \n",
       "585           97          88            0             0     1        0     0   \n",
       "584           93          87            0             0     1        0     0   \n",
       "583            0           0            0             0     0        0     0   \n",
       "\n",
       "     time_to_station_min  room  area_m2  direction  type  address  \\\n",
       "284                   13    10       82          8     1       33   \n",
       "239                   11     3      118          8     1       27   \n",
       "282                    3     1       76          7     1       36   \n",
       "238                   15     1      118          8     1       27   \n",
       "440                    1     2      128          5     1       22   \n",
       "..                   ...   ...      ...        ...   ...      ...   \n",
       "578                    4     7      184          4     1       34   \n",
       "579                   13     7      175          4     1       52   \n",
       "585                   13     8      185          0     2       29   \n",
       "584                   18     4      171          8     1       18   \n",
       "583                    0     5      170          8     1       37   \n",
       "\n",
       "     market_rent  rent_difference  \n",
       "284    52.727688        -8.727688  \n",
       "239    47.514988        -8.514988  \n",
       "282    50.893050        -7.893050  \n",
       "238    46.617498        -7.617498  \n",
       "440    78.601456        -7.601456  \n",
       "..           ...              ...  \n",
       "578   101.890808        11.109192  \n",
       "579   101.620807        11.379193  \n",
       "585   104.618361        13.381639  \n",
       "584   102.908852        14.091148  \n",
       "583   101.312785        14.687215  \n",
       "\n",
       "[586 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0537d089-888f-43a6-8ed2-c704b6f812b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cef5c-7f1a-4fb0-88b3-2287214fed43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484321c0-1e17-4567-8595-85b1fd1c758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da3c8dd5-3417-4316-8ad0-e76fe2c69eae",
   "metadata": {},
   "source": [
    "# GCPを利用した。AutoMLによる分析自動化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fbf1a-a6d5-4291-9966-e0adcc5aa755",
   "metadata": {},
   "source": [
    "aiplatform.googleapis.com：Google Cloud Platform (GCP) 上で提供される、機械学習のためのプラットフォームサービスの1つで、AutoML や TensorFlow などの機械学習ツールを提供している。  \n",
    "このサービスを使用することで、機械学習モデルのトレーニング、モデルのデプロイ、予測の実行などが簡単に行える。\n",
    "\n",
    "#### 手順1  \n",
    "Google Cloud Consoleにログインし、AutoML Tablesの画面に移動  \n",
    "#### 手順2  \n",
    "左側のメニューから「データセット」をクリックし、新しいデータセットを作成します。データセット名、説明、ターゲットカラムなどの詳細を設定  \n",
    "今回は  \n",
    "データセット名：「test_dataset_01」  \n",
    "データタイプと目標の選択：表形式の「回帰/分類」\n",
    "リージョン：us-central1(アイオワ)  \n",
    "データセットを作成を押す。  \n",
    "データソースを選択：「Cloud Storage から CSV ファイルを選択」\n",
    "インポートファイルのパスを'参照'から行う。  \n",
    "#### 手順3  \n",
    "データのアップロードが完了したら、「モデルのトレーニング」をクリックして、AutoMLがモデルを自動的にトレーニングするように指示 \n",
    "具体的には  \n",
    "Dataset：test_dataset_01  \n",
    "Objective：Regression  \n",
    "最適化の目標：RMSE(外れ値があるとは考えにくいため。本来は候補の指標はそれぞれ試した方が良い。)\n",
    "#### 手順4  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f774371-3e0c-4f0a-a494-6bc94dca9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 1.0.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: lightgbm, scikit-learn-intelex, xfeat\n"
     ]
    }
   ],
   "source": [
    "pip show scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef396db0-225e-4194-90f1-37b5d277fd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 3.3.3\n",
      "Summary: LightGBM Python Package\n",
      "Home-page: https://github.com/microsoft/LightGBM\n",
      "Author: \n",
      "Author-email: \n",
      "License: The MIT License (Microsoft)\n",
      "Location: c:\\users\\t-miy\\appdata\\roaming\\python\\python39\\site-packages\n",
      "Requires: numpy, scikit-learn, scipy, wheel\n",
      "Required-by: xfeat\n"
     ]
    }
   ],
   "source": [
    "pip show lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659e4d8-24cd-4f45-9cb1-a94f903b1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8c40e-2979-41de-bb60-f877fd6596cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def encode_categorical(df,cols):\n",
    "        for col in cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = pd.Series(le.fit_transform(df[col]))\n",
    "    \n",
    "        return df\n",
    "    df1 = encode_categorical(df1,cols=[\"scraping_date\",\"name\",\"line\",\"station\",\"move\",\"room\",\"direction\",\"type\",\"address\"])\n",
    "\n",
    "    X = df1.drop('price_10k', axis=1)\n",
    "    y = df1['price_10k']\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    df2 = df1.copy()\n",
    "    df2['market_rent'] = model.predict(X)\n",
    "    df2['price_10k'] = df2['price_10k'].astype(float)\n",
    "    df2['market_rent'] = df2['market_rent'].astype(float)\n",
    "\n",
    "    df2['rent_difference'] = df2['price_10k'] - df2['market_rent']\n",
    "\n",
    "    df2_sorted = df2.sort_values('rent_difference', ascending=True)\n",
    "    write_csv_to_gcs(df2_sorted, 'suumo_bucket01', 'suumo_mp_data/mp_file01.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
